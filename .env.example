# =========================
# 大模型（OpenAI 兼容）基础配置
# =========================
LLM_API_KEY=
LLM_API_BASE=
LLM_MODEL=

# 兼容 OpenAI 官方变量
OPENAI_API_KEY=
OPENAI_BASE_URL=

# =========================
# Embedding 配置（本地 RAG 需要；二选一：本地模型 或 远程 OpenAI 兼容接口）
# =========================
# 本地 embedding（推荐；指定模型名或本地路径，支持逗号分隔候选）
EMBEDDING_USE_LOCAL=true                            # 使用本地 embedding 模型（优先）
EMBEDDING_LOCAL_MODEL=./models/msmarco-roberta-base-ance-firstp   # 本地 embedding 模型路径/名称
EMBEDDING_LOCAL_MODELS=                             # 逗号分隔的本地模型候选（按顺序尝试）
# 远程 embedding（OpenAI 兼容；仅当 EMBEDDING_USE_REMOTE=true 时生效）
EMBEDDING_USE_REMOTE=false                          # 是否使用远程 embedding
EMBEDDING_API_KEY=
EMBEDDING_API_BASE=
EMBEDDING_MODEL=text-embedding-3-small              # 远程 embedding 模型名称
# 向量库持久化目录（留空则使用内存，不持久化）
CHROMA_PATH=./data/chroma                           # Chroma 存储路径

# =========================
# RAG 配置（开关与数据源）
# =========================
# 模式：local（本地 Chroma）| remote（远程 HTTP）| off（关闭 RAG）
RAG_PROVIDER=local                                  # local|remote|off
# 本地 RAG 选项（local 时有效）
RAG_TWEET_FILE=                                     # 可选，舆情语料文件（默认 data/tweets.json）
RAG_COLLECTION_SAFE=                                # 可选，自定义安全集合名
RAG_COLLECTION_UNSAFE=                              # 可选，自定义不安全集合名
RAG_AUTO_INGEST=true          # quickstart 启动时自动 ingest
RAG_RESET_COLLECTIONS=false     # ingest 前清空集合，避免重复
RAG_RESET_STORAGE=false        # true 时清空 CHROMA_PATH 后再 ingest
# 远程 RAG（remote 时有效，POST {query, top_k}）
RAG_REMOTE_URL=
RAG_REMOTE_API_KEY=

# =========================
# 视觉管线配置（本地 Caption + 远程判定，或远程多模态直判）
# =========================
# 开关：
#   VISION_ENABLED=false 时完全跳过视觉一致性检测
#   VISION_PIPELINE_MODE=caption_text ：本地 Caption/VLM 生成描述 + 远程“文本判定”LLM 检查一致性
#   VISION_PIPELINE_MODE=multimodal ：直接调用远程多模态模型（图+文一起判定，不走本地 Caption）
VISION_ENABLED=true                                 # 是否开启视觉一致性检测
VISION_PIPELINE_MODE=caption_text                   # caption_text（本地 Caption + 文本判定）| multimodal（远程多模态直判）
# 本地 Caption/VLM 描述（默认 Florence 生成描述，caption_text 模式下总是执行）
VISION_LOCAL_CAPTION_MODEL=./models/florence-2-base # 本地 caption/VLM 模型路径/名称
# 远程文本判定：用 LLM 对 “描述 vs 用户文本” 判定一致性
VISION_REMOTE_TEXT_API_KEY=
VISION_REMOTE_TEXT_API_BASE=
VISION_REMOTE_TEXT_MODEL=
# 远程多模态判定：直接发图+文给多模态模型（默认 glm-4v-flash，智谱）
VISION_REMOTE_MM_API_KEY=
VISION_REMOTE_MM_API_BASE=
VISION_REMOTE_MM_MODEL=glm-4v-flash

# =========================
# 默认防御开关
# =========================
DEFENSE_DEFAULT_ON=true                     # 默认是否开启防御
TOOL_CALL_MAX_ROUNDS=3                      # LLM 多轮 tool_call 上限
LOG_LEVEL=WARNING                           # 日志等级

# =========================
# 账本文件路径（可选）
# =========================
# 默认使用 data/ledger/ledger.json 作为初始化种子；可设 LEDGER_DB 指向 SQLite 账本文件。
LEDGER_FILE=                                # 账本种子 JSON（可选）
LEDGER_DB=                                  # SQLite 账本文件路径
LEDGER_SNAPSHOT_RETENTION=5                 # 快照保留份数

# =========================
# MCP 客户端
# =========================
# 常驻 MCP 服务（推荐）：先在一端启动 MCP，再在前端侧配置 URL。
#   MCP_TRANSPORT=sse MCP_HOST=0.0.0.0 MCP_PORT=8001 MCP_SSE_PATH=/sse python -m src.simulation.server
# 前端/.env 设置 URL（如需鉴权头，设 MCP_SERVER_HEADERS='{\"Authorization\":\"Bearer xxx\"}'）
MCP_SERVER_URL=http://127.0.0.1:8001/sse
# 如需回退到本地子进程模式（非推荐）再设置： MCP_SERVER_CMD=python -m src.simulation.server
MCP_SERVER_CMD=
HEALTH_HOST=0.0.0.0
HEALTH_PORT=8081
TOOL_CALL_TIMEOUT=15
TOOL_CALL_RETRIES=1

# 双通道（防御/无防御）MCP 服务端与账本
MCP_SERVER_URL_SAFE=
MCP_SERVER_URL_UNSAFE=
MCP_HOST_SAFE=
MCP_HOST_UNSAFE=
MCP_PORT_SAFE=
MCP_PORT_UNSAFE=
MCP_SSE_PATH_SAFE=
MCP_SSE_PATH_UNSAFE=
LEDGER_DB_SAFE=
LEDGER_DB_UNSAFE=
HEALTH_PORT_SAFE=
HEALTH_PORT_UNSAFE=
